# Task 1: Dataset Analysis

## Datasets I analyzed:
- LJSpeech: 24hr single female, clean English
- VCTK: 109 speakers, UK accents  
- LibriTTS: 585hr audiobooks
- Hi-Fi: 292hr studio quality
- Common Voice: Multilingual crowdsourced

Clean data = clear voice. Noisy data = muffled voice.

# ğŸ—£ï¸ TTS Dataset Analysis (Simplified Summary)

## ğŸ“˜ Dataset Overview

| Dataset Name | Description | Use Case |
|---------------|--------------|-----------|
| **LJSpeech** | Single female (US English), 24h clean studio audio | Clear single-speaker TTS |
| **VCTK** | 109 UK English speakers, 44h total | Accent & multi-speaker TTS |
| **LibriTTS** | 2,456 speakers, 585h diverse audio | Robust large-scale models |
| **Hi-Fi Multi-Speaker** | 10 pro speakers, 292h | Premium quality, emotional TTS |
| **HUI German Corpus** | Multi-speaker German dataset with aligned text | German TTS training |
| **Common Voice** | 9,000+ hours across 60+ languages | Multilingual / low-resource TTS |

---

## ğŸ™ï¸ Voice Quality Factors

- **Clarity:**  
  High SNR (>20â€¯dB) and sample rate (22â€¯kHz+) â†’ crisp, clear audio.

- **Naturalness:**  
  Prosody (rhythm, pauses, intonation) = human-like speech.

- **Accent:**  
  Output accent depends on dataset source (US, UK, etc.).

- **Pitch & Timbre:**  
  - Female range: 180â€“250â€¯Hz  
  - Male range: 100â€“180â€¯Hz  
  Voice tone comes from speakersâ€™ frequency and vocal traits.

- **Emotion:**  
  Expressive datasets = emotional, realistic voices.

---

## ğŸ§  Dataset Selection Tips

- Match **language**, **accent**, & **speaker style** to your target voice.  
- Use **expressive** data for emotional TTS; **neutral** for assistants.  
- Prefer **high-quality studio recordings** (>20â€¯dB SNR).  
- **Single-speaker** â†’ consistent quality.  
- **Multi-speaker** â†’ diversity and accent coverage.  
- Collect **10â€“25â€¯h+** for good results; **100â€¯h+** for multi-speaker strength.

---

## âš™ï¸ Data Preparation Pipeline

1. Clean dataset â€” remove noise & misalignments.  
2. Resample audio to 16â€¯kHzâ€¯/â€¯22.05â€¯kHz.  
3. Normalize loudness to -20â€¯dBFS & trim silence below -40â€¯dB.  
4. Text normalization (expand numbers, abbreviations, etc.).  
5. Forced alignment with **Montreal Forced Aligner**.  
6. Segment audio into 5â€“15â€¯sec clips.  
7. Extract **Mel-spectrograms** (80 mel bins, 25â€¯ms window, 10â€¯ms hop).  
8. Split:
   - 90% â†’ Train  
   - 5% â†’ Validation  
   - 5% â†’ Test  

---

## ğŸ’¡ Key Takeaways

- Good **data = good TTS quality**.  
- **LJSpeech** â†’ natural single voice.  
- **VCTK** â†’ diverse accent modeling.  
- **LibriTTS** â†’ large, strong baseline dataset.  
- **Clean preprocessing** ensures consistent speech synthesis.

---

ğŸ“ *Suggested Filename:* `TTS_Dataset_Analysis.md`





